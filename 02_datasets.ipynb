{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1c7ad9-ec91-4840-89a5-201e1158e55f",
   "metadata": {},
   "source": [
    "# datasets\n",
    "\n",
    "> Provide some convenience functionality for dealing with example datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37779ce1-d503-4416-874b-9f8a22cc916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab4245-7823-42c0-947f-90fd338ad53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e23986-8164-4fc1-a34a-6d6930af73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "import xml.etree.ElementTree as _et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f93ae-ab8c-4e3e-92d0-30b635d8602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ReutersParser:\n",
    "    _broken = (\n",
    "        b\"&#1;\",\n",
    "        b\"&#2;\",\n",
    "        b\"&#3;\",\n",
    "        b\"\\xfc\",\n",
    "        b\"&#5;\",\n",
    "        b\"&#22;\",\n",
    "        b\"&#27;\",\n",
    "        b\"&#30;\",\n",
    "        b\"&#31;\",\n",
    "        b\"&#127;\",\n",
    "    )\n",
    "\n",
    "    def cleanup_sgml(self, chunk):\n",
    "        for item in self._broken:\n",
    "            chunk = chunk.replace(item, b\"\")\n",
    "        chunk = chunk.replace(b'<!DOCTYPE lewis SYSTEM \"lewis.dtd\">', b\"<document>\")\n",
    "        return b\"%s</document>\" % chunk\n",
    "\n",
    "    def get_topics(self, topics):\n",
    "        return [topic.text for topic in topics]\n",
    "\n",
    "    def get_text(self, text):\n",
    "        tagmap = dict.fromkeys((\"title\", \"dateline\", \"body\"))\n",
    "        for item in text:\n",
    "            tag = item.tag.lower()\n",
    "            if tag in tagmap:\n",
    "                tagmap[tag] = item.text\n",
    "        return tagmap\n",
    "\n",
    "    def parse_doc(self, elem):\n",
    "        doc = {}\n",
    "        doc[\"attrs\"] = dict(elem.items())\n",
    "        for item in elem:\n",
    "            if item.tag == \"TOPICS\":\n",
    "                doc[\"topics\"] = self.get_topics(item)\n",
    "            elif item.tag == \"DATE\":\n",
    "                doc[\"date\"] = item.text\n",
    "            elif item.tag == \"TEXT\":\n",
    "                doc.update(self.get_text(item))\n",
    "        return doc\n",
    "\n",
    "    def parse_sgml(self, filename):\n",
    "        stream = StringIO(\n",
    "            self.cleanup_sgml(open(filename, \"rb\").read()).decode(\"utf-8\")\n",
    "        )\n",
    "        for _, elem in _et.iterparse(stream):\n",
    "            if elem.tag == \"REUTERS\":\n",
    "                yield self.parse_doc(elem)\n",
    "\n",
    "class ReutersCorpus:\n",
    "    def __init__(self, raw_docs, multiclass=False, filter_empty_cats=True):\n",
    "        self.topics = {}\n",
    "        self.cat_to_topic = {}\n",
    "        self.target_names = []\n",
    "\n",
    "        self.docs = list(self.get_docs(raw_docs))\n",
    "        if multiclass:\n",
    "            self.docs = self.filter_multi_label(self.docs)\n",
    "\n",
    "        # before filtering empty cats it's 9603 train and 3299 test documents\n",
    "        # after filtering there are 7770 train and 3019 test documents left\n",
    "        if filter_empty_cats:\n",
    "            self.docs = self.filter_empty_cats(self.docs)\n",
    "\n",
    "        # labels have to be without gaps\n",
    "        self._renumber_topics()\n",
    "\n",
    "    def _renumber_topics(self):\n",
    "        self.renumbered_cat_to_topic = {}\n",
    "        self.renumbered_topics = {}\n",
    "        self.renumbered_lookup = {}\n",
    "        num = 0\n",
    "        for doc in self.docs:\n",
    "            new_cats = []\n",
    "            for cat in doc[\"cats\"]:\n",
    "                if cat not in self.renumbered_lookup:\n",
    "                    topic = self.cat_to_topic[cat]\n",
    "                    self.renumbered_cat_to_topic[num] = topic\n",
    "                    self.renumbered_topics[topic] = num\n",
    "                    self.renumbered_lookup[cat] = num\n",
    "                    num += 1\n",
    "                new_cat = self.renumbered_lookup[cat]\n",
    "                new_cats.append(new_cat)\n",
    "            doc[\"cats\"] = new_cats\n",
    "\n",
    "    def _add_text(self, doc):\n",
    "        # doc[\"text\"] = \" \".join([doc.get(tag) or \"\" for tag in\n",
    "        #    (\"title\", \"dateline\", \"body\")])\n",
    "        doc[\"text\"] = \" \".join([doc.get(tag) or \"\" for tag in (\"dateline\", \"body\")])\n",
    "        title = \" \".join([doc.get(\"title\") or \"\" for i in range(1)])\n",
    "        doc[\"text\"] = \"%s %s\" % (title, doc[\"text\"])\n",
    "\n",
    "    def _add_modapte(self, doc):\n",
    "        attrs = doc[\"attrs\"]\n",
    "        doc[\"modapte\"] = \"unused\"\n",
    "        if attrs[\"LEWISSPLIT\"] == \"TRAIN\" and attrs[\"TOPICS\"] == \"YES\":\n",
    "            doc[\"modapte\"] = \"train\"\n",
    "        elif attrs[\"LEWISSPLIT\"] == \"TEST\" and attrs[\"TOPICS\"] == \"YES\":\n",
    "            doc[\"modapte\"] = \"test\"\n",
    "\n",
    "    def _add_topics(self, doc):\n",
    "        doc[\"cats\"] = []\n",
    "        for topic in doc[\"topics\"]:\n",
    "            if topic not in self.topics:\n",
    "                self.target_names.append(topic)\n",
    "                topic_id = len(self.target_names)\n",
    "                self.topics[topic] = topic_id\n",
    "                self.cat_to_topic[topic_id] = topic\n",
    "            topic_id = self.topics[topic]\n",
    "            doc[\"cats\"].append(topic_id)\n",
    "\n",
    "    def get_docs(self, documents):\n",
    "        modifiers = [self._add_text, self._add_modapte, self._add_topics]\n",
    "        for doc in documents:\n",
    "            for modifier in modifiers:\n",
    "                modifier(doc)\n",
    "            if doc[\"modapte\"] != \"unused\":\n",
    "                yield doc\n",
    "\n",
    "    def filter_empty_cats(self, docs):\n",
    "        # modapte yields 90 categories with 1 train and test doc at least\n",
    "        train, test = set(), set()\n",
    "        for doc in docs:\n",
    "            if doc[\"modapte\"] == \"train\":\n",
    "                for cat in doc[\"cats\"]:\n",
    "                    train.add(cat)\n",
    "            elif doc[\"modapte\"] == \"test\":\n",
    "                for cat in doc[\"cats\"]:\n",
    "                    test.add(cat)\n",
    "        valid_cats = train.intersection(test)\n",
    "        self.valid_cats = valid_cats\n",
    "        new_docs = []\n",
    "        for doc in docs:\n",
    "            doc[\"cats\"] = [c for c in doc[\"cats\"] if c in valid_cats]\n",
    "            if len(doc[\"cats\"]) > 0:\n",
    "                new_docs.append(doc)\n",
    "        return new_docs\n",
    "\n",
    "    def filter_multi_label(self, docs):\n",
    "        filtered_docs = []\n",
    "        for doc in docs:\n",
    "            if len(doc[\"cats\"]) == 1:\n",
    "                filtered_docs.append(doc)\n",
    "        return filtered_docs\n",
    "\n",
    "    @property\n",
    "    def number_of_samples(self):\n",
    "        return len(self.docs)\n",
    "\n",
    "    @property\n",
    "    def number_of_classes(self):\n",
    "        return len([name for name, count in self.topics.items() if count > 1])\n",
    "\n",
    "    @property\n",
    "    def texts(self):\n",
    "        return [d[\"text\"] for d in self.docs]\n",
    "\n",
    "    @property\n",
    "    def topic_counts(self):\n",
    "        counts = Counter()\n",
    "        for doc in self.docs:\n",
    "            for topic in doc[\"cats\"]:\n",
    "                counts[topic] += 1\n",
    "        return counts\n",
    "\n",
    "    def top_n(self, n=10):\n",
    "        topic_lookup = {v: k for k, v in self.renumbered_topics.items()}\n",
    "        top_topics = sorted(\n",
    "            [(v, k) for k, v in self.topic_counts.items()], reverse=True\n",
    "        )[:n]\n",
    "        top_n_topics = [\n",
    "            (topic_lookup[topic_id], topic_id) for (count, topic_id) in top_topics[:n]\n",
    "        ]\n",
    "        top_n_ids = [topic_id for (name, topic_id) in top_n_topics]\n",
    "        top_n_names = [name for name, topic_id in top_n_topics]\n",
    "        return top_n_ids, top_n_names\n",
    "\n",
    "    def get_single_label(self, docs, top_n):\n",
    "        labels = []\n",
    "        for doc in docs:\n",
    "            # default label is the first one\n",
    "            label = doc[\"cats\"][0]\n",
    "            for cat in doc[\"cats\"]:\n",
    "                if cat in top_n:\n",
    "                    label = cat\n",
    "            labels.append(label)\n",
    "        return labels\n",
    "\n",
    "    def get_labels(self, docs):\n",
    "        labels = []\n",
    "        for doc in docs:\n",
    "            labels.append(doc[\"cats\"])\n",
    "        return labels\n",
    "\n",
    "    def split_modapte(self):\n",
    "        train, test = [], []\n",
    "        for doc in self.docs:\n",
    "            if doc[\"modapte\"] == \"train\":\n",
    "                train.append(doc)\n",
    "            elif doc[\"modapte\"] == \"test\":\n",
    "                test.append(doc)\n",
    "        return train, test\n",
    "\n",
    "    def build_dataframe(self, pd=None, n=10):\n",
    "        if pd is None:\n",
    "            # the df parameter is only there to avoid a hard dependency to pandas\n",
    "            return None\n",
    "        top_ten_ids, top_ten_names = self.top_n(n=n)\n",
    "        train_docs, test_docs = self.split_modapte()\n",
    "        docs = train_docs + test_docs\n",
    "        train_labels = self.get_labels(train_docs)\n",
    "        test_labels = self.get_labels(test_docs)\n",
    "        labels = train_labels + test_labels\n",
    "\n",
    "#        labels = train_labels + test_labels\n",
    "#        label_lookup = {}\n",
    "#        num = 0\n",
    "#        for label in sorted(labels):\n",
    "#            if label not in label_lookup:\n",
    "#                label_lookup[label] = num\n",
    "#                num += 1\n",
    "#\n",
    "#        topic_lookup = {v: k for k, v in self.topics.items()}\n",
    "#        orig_labels = [topic_lookup[l] for l in labels]\n",
    "#\n",
    "#        labels = [label_lookup[l] for l in labels]\n",
    "#        train_labels = [label_lookup[l] for l in train_labels]\n",
    "#        test_labels = [label_lookup[l] for l in test_labels]\n",
    "#        top_ten_ids = [label_lookup[tid] for tid in top_ten_ids]\n",
    "\n",
    "        orig_labels = []\n",
    "        for cats in labels:\n",
    "            topics = [self.renumbered_cat_to_topic[c] for c in cats]\n",
    "            orig_labels.append(topics)\n",
    "\n",
    "        # build dataframe\n",
    "        df = pd.DataFrame()\n",
    "        df[\"modapte\"] = [d[\"modapte\"] for d in docs]\n",
    "        df[\"category\"] = orig_labels\n",
    "        df[\"label\"] = train_labels + test_labels\n",
    "        df[\"date\"] = [d[\"date\"] for d in docs]\n",
    "        df[\"title\"] = [d[\"title\"] for d in docs]\n",
    "        df[\"dateline\"] = [d[\"dateline\"] for d in docs]\n",
    "        df[\"body\"] = [d[\"body\"] for d in docs]\n",
    "        df[\"newid\"] = [d[\"attrs\"][\"NEWID\"] for d in docs]\n",
    "        df[\"date\"] = pd.to_datetime(\n",
    "            df.date.str.split(\".\").apply(lambda x: x[0].lstrip()),\n",
    "            format=\"%d-%b-%Y %H:%M:%S\",\n",
    "        )\n",
    "        df[\"wd_name\"] = df.date.dt.day_name()\n",
    "        return df, top_ten_ids, train_labels, test_labels\n",
    "\n",
    "\n",
    "def build_reuters_dataframe(docs, topics, train_labels, test_labels, top_ten_ids, pd=None):\n",
    "    if pd is None:\n",
    "        # the df parameter is only there to avoid a hard dependency to pandas\n",
    "        return None    \n",
    "    # remove gaps\n",
    "    labels = train_labels + test_labels\n",
    "    label_lookup = {}\n",
    "    num = 0\n",
    "    for label in sorted(labels):\n",
    "        if label not in label_lookup:\n",
    "            label_lookup[label] = num\n",
    "            num += 1\n",
    "\n",
    "    topic_lookup = {v: k for k, v in topics.items()}\n",
    "    orig_labels = [topic_lookup[l] for l in labels]\n",
    "\n",
    "    labels = [label_lookup[l] for l in labels]\n",
    "    train_labels = [label_lookup[l] for l in train_labels]\n",
    "    test_labels = [label_lookup[l] for l in test_labels]\n",
    "    top_ten_ids = [label_lookup[tid] for tid in top_ten_ids]\n",
    "\n",
    "    # build dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df[\"modapte\"] = [d[\"modapte\"] for d in docs]\n",
    "    df[\"category\"] = orig_labels\n",
    "    df[\"label\"] = train_labels + test_labels\n",
    "    df[\"date\"] = [d[\"date\"] for d in docs]\n",
    "    df[\"title\"] = [d[\"title\"] for d in docs]\n",
    "    df[\"dateline\"] = [d[\"dateline\"] for d in docs]\n",
    "    df[\"body\"] = [d[\"body\"] for d in docs]\n",
    "    df[\"newid\"] = [d[\"attrs\"][\"NEWID\"] for d in docs]\n",
    "    df[\"date\"] = pd.to_datetime(\n",
    "        df.date.str.split(\".\").apply(lambda x: x[0].lstrip()),\n",
    "        format=\"%d-%b-%Y %H:%M:%S\",\n",
    "    )\n",
    "    df[\"wd_name\"] = df.date.dt.day_name()\n",
    "    return df, top_ten_ids, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343b1fe-ce63-46e4-8d64-563d24779b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
